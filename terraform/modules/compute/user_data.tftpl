#!/bin/bash

# Log everything
exec > >(tee /var/log/user-data.log|logger -t user-data -s 2>/dev/console) 2>&1

echo "Starting User Data Script..."

# 1. Install Docker
# 1. Install Docker & AWS CLI
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh
usermod -aG docker ubuntu
snap install aws-cli --classic

# 2. Fetch Secrets from SSM
# 2. Fetch Secrets from SSM
# Use token for IMDSv2
TOKEN=`curl -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 21600"`
REGION=$(curl -H "X-aws-ec2-metadata-token: $TOKEN" -s http://169.254.169.254/latest/meta-data/placement/region)
echo "Fetching secrets from Region: $REGION"

# Explicitly export region for aws cli
export AWS_DEFAULT_REGION=$REGION

DB_PASSWORD=$(aws ssm get-parameter --name "/${project_name}/db_password" --with-decryption --query "Parameter.Value" --output text)
SECRET_KEY=$(aws ssm get-parameter --name "/${project_name}/secret_key" --with-decryption --query "Parameter.Value" --output text)
SES_USER=$(aws ssm get-parameter --name "/${project_name}/ses_user" --with-decryption --query "Parameter.Value" --output text)
SES_PASSWORD=$(aws ssm get-parameter --name "/${project_name}/ses_password" --with-decryption --query "Parameter.Value" --output text)

# Verify we got the password (don't log it, just check length)
if [ -z "$DB_PASSWORD" ]; then
  echo "CRITICAL ERROR: Failed to fetch DB_PASSWORD from SSM."
fi

# 3. Create Docker Compose File
mkdir -p /home/ubuntu/app
cd /home/ubuntu/app

cat <<EOT > docker-compose.yml
version: '3.8'
services:
  backend:
    image: jywong75/neurasky-backend:Production
    container_name: neurasky_backend
    restart: always
    ports:
      - "8000:8000"
    environment:
      - DB_HOST=${db_host}
      - DB_PORT=3306
      - DB_NAME=${db_name}
      - DB_USER=${db_user}
      - DB_PASSWORD=$DB_PASSWORD
      - SECRET_KEY=$SECRET_KEY
      # AWS SES
      - EMAIL_BACKEND=django.core.mail.backends.smtp.EmailBackend
      - AWS_SES_ENDPOINT=email-smtp.ap-southeast-1.amazonaws.com
      - AWS_SES_USER=$SES_USER
      - AWS_SES_PASSWORD=$SES_PASSWORD
      - DEFAULT_FROM_EMAIL=NeuraSky Support <support@neurasky.click>
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health/"]
      interval: 30s
      timeout: 10s
      retries: 5

  frontend:
    image: jywong75/neurasky-frontend:Production
    container_name: neurasky_frontend
    restart: always
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=https://${domain_name}
    depends_on:
      - backend
EOT

# 4. Auto-Seeding Database
echo "Checking for database data..."
# Install MySQL Client
apt-get update && apt-get install mariadb-client -y

# Wait for DB to be reachable
echo "Waiting for DB at ${db_host}..."
# Use -p"$DB_PASSWORD" (no space) to pass password securely
until mysql -h ${db_host} -u ${db_user} -p"$DB_PASSWORD" -e "SELECT 1"; do
  echo "Database not ready, retrying..."
  sleep 5
done

# Check if tables exist
TABLE_COUNT=$(mysql -h ${db_host} -u ${db_user} -p"$DB_PASSWORD" ${db_name} -N -e "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = '${db_name}';")

if [ "$TABLE_COUNT" -eq "0" ]; then
  echo "Database is empty. Attempting to seed..."
  
  # Use exact bucket name passed from Terraform
  DATA_BUCKET="${data_bucket_name}"
  
  echo "Downloading dump from $DATA_BUCKET..."
  aws s3 cp s3://$DATA_BUCKET/neuraskyDB.sql neuraskyDB.sql
  
  if [ -f "neuraskyDB.sql" ]; then
      echo "Importing dump..."
      mysql -h ${db_host} -u ${db_user} -p"$DB_PASSWORD" ${db_name} < neuraskyDB.sql
      echo "Database seeded successfully!"
  else
      echo "No neuraskyDB.sql found in bucket. Skipping import."
  fi
else
  echo "Database already contains $TABLE_COUNT tables. Skipping seeding."
fi

# 4. Start Application
docker compose up -d

# 5. Wait loop
echo "Waiting for services to start..."
sleep 20
docker compose ps
