{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c414e0-9671-4105-84c9-7d4738b7e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a8129-fdcb-4c1b-9af8-ef68cf9c7a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the parquet files you want to load\n",
    "data_files = [\n",
    "    'dataset/Combined_Flights_2018.parquet',\n",
    "    'dataset/Combined_Flights_2019.parquet',\n",
    "    'dataset/Combined_Flights_2020.parquet',\n",
    "    'dataset/Combined_Flights_2021.parquet',\n",
    "    'dataset/Combined_Flights_2022.parquet'\n",
    "]\n",
    "\n",
    "# --- IMPORTANT WARNING ---\n",
    "# This is a LOT of data. This step might take a few minutes\n",
    "# and use a lot of your computer's RAM.\n",
    "# If your computer crashes, try it with just ONE file first:\n",
    "# data_files = ['dataset/Combined_Flights_2022.parquet']\n",
    "\n",
    "# Loop through each file, load it, and add it to a list\n",
    "dataframes_list = []\n",
    "for file in data_files:\n",
    "    print(f\"Loading {file}...\")\n",
    "    df = pd.read_parquet(file)\n",
    "    dataframes_list.append(df)\n",
    "\n",
    "# Combine all DataFrames into one single, massive DataFrame\n",
    "print(\"Combining all datasets...\")\n",
    "df = pd.concat(dataframes_list, ignore_index=True)\n",
    "\n",
    "print(f\"Data loaded. Total shape: {df.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ef65c-5be8-4822-ad2d-db7d10bc3c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define your target (what we want to predict)\n",
    "#    From your file: \"DepDel15\" is \"Departure Delay Indicator, 15 Minutes or More (1=Yes)\"\n",
    "target = 'DepDel15'\n",
    "\n",
    "# 2. Define your features (the inputs for the model)\n",
    "#    Using names from your RECORD LAYOUT file:\n",
    "features = [\n",
    "    'Month',\n",
    "    'DayOfWeek',\n",
    "    'CRSDepTime',        # Scheduled Departure Time\n",
    "    'Operating_Airline', # Unique airline code\n",
    "    'Origin',            # Origin Airport Code\n",
    "    'Dest'               # Destination Airport Code\n",
    "]\n",
    "\n",
    "# 3. Define which of those features are categorical (text-based)\n",
    "categorical_features = ['Operating_Airline', 'Origin', 'Dest']\n",
    "\n",
    "# 4. Clean the data\n",
    "#    - Drop rows where our target or features are missing\n",
    "print(f\"Original size: {df.shape}\")\n",
    "df = df.dropna(subset=features + [target])\n",
    "print(f\"Size after dropping missing values: {df.shape}\")\n",
    "\n",
    "# 5. Create our X (features) and y (target)\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# 6. We must convert categories to numbers. An Encoder does this.\n",
    "#    We use OrdinalEncoder because LightGBM is smart enough to handle it.\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "X[categorical_features] = encoder.fit_transform(X[categorical_features])\n",
    "\n",
    "print(\"Data prepared and encoded.\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1861f15d-a752-49c0-b246-91881ccf21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Initialize the LightGBM Classifier\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective='binary',  # We are predicting 0 or 1 (binary)\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1            # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Train the model!\n",
    "print(\"Starting model training... (this may take a few minutes)\")\n",
    "model.fit(X_train, y_train, \n",
    "          categorical_feature=categorical_features  # Pass the correct feature names\n",
    "         )\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b83de-8585-4c81-a0d7-cb1e73f46173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "print(\"Making predictions...\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Check the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad99449-268d-4b73-86ca-6e4a1d1de3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "joblib.dump(model, 'api/flight_delay_model.joblib')\n",
    "\n",
    "# Save the encoder to a file\n",
    "joblib.dump(encoder, 'api/flight_data_encoder.joblib')\n",
    "\n",
    "print(\"Model and encoder saved to api/ folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
