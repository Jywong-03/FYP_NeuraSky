{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Enhanced ML Model Training for Flight Delay Prediction\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                           confusion_matrix, classification_report, roc_auc_score, roc_curve)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üöÄ Starting Enhanced ML Model Training for Flight Delay Prediction\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Data\n",
    "print(\"\\nüìÅ Loading data...\")\n",
    "DATA_DIR = 'dataset'\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(f\"‚ùå Dataset directory '{DATA_DIR}' not found!\")\n",
    "    print(\"üí° Please run 'python generate_enhanced_dataset.py' first\")\n",
    "    exit(1)\n",
    "\n",
    "csv_files = glob.glob(os.path.join(DATA_DIR, \"*.csv\"))\n",
    "print(f\"üìÑ Found {len(csv_files)} CSV files: {[os.path.basename(f) for f in csv_files]}\")\n",
    "\n",
    "df_list = []\n",
    "for filename in csv_files:\n",
    "    df_temp = pd.read_csv(filename)\n",
    "    df_list.append(df_temp)\n",
    "    print(f\"   ‚úÖ Loaded {os.path.basename(filename)}: {len(df_temp):,} records\")\n",
    "\n",
    "if not df_list:\n",
    "    raise FileNotFoundError(\"No CSV files found in dataset directory.\")\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "print(f\"üìä Total dataset size: {df.shape[0]:,} rows, {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Quality Check\n",
    "print(\"\\nüîç Data Quality Check:\")\n",
    "missing_values = df.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(\"‚ö†Ô∏è  Missing values found:\")\n",
    "    missing_cols = missing_values[missing_values > 0]\n",
    "    for col, count in missing_cols.items():\n",
    "        print(f\"   {col}: {count:,}\")\n",
    "else:\n",
    "    print(\"‚úÖ No missing values found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define target and features\n",
    "target = 'DepDel15'\n",
    "features = [\n",
    "    'Month',\n",
    "    'DayOfWeek', \n",
    "    'CRSDepTime',\n",
    "    'Operating_Airline',\n",
    "    'Origin',\n",
    "    'Dest',\n",
    "    'Distance'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Add engineered features BEFORE encoding\n",
    "print(\"\\nüîß Feature Engineering...\")\n",
    "\n",
    "# Time-based features\n",
    "df['Hour'] = df['CRSDepTime'] // 100\n",
    "df['Minute'] = df['CRSDepTime'] % 100\n",
    "\n",
    "# Create TimeOfDay feature BEFORE encoding\n",
    "df['TimeOfDay'] = pd.cut(df['Hour'], \n",
    "                        bins=[0, 6, 12, 18, 24], \n",
    "                        labels=['Night', 'Morning', 'Afternoon', 'Evening'],\n",
    "                        include_lowest=True)\n",
    "\n",
    "# Route complexity\n",
    "df['IsInternational'] = (~df['Origin'].isin(['KUL', 'PEN', 'BKI', 'KCH', 'LGK', 'JHB'])) | \\\n",
    "                        (~df['Dest'].isin(['KUL', 'PEN', 'BKI', 'KCH', 'LGK', 'JHB']))\n",
    "\n",
    "# Peak hour indicator\n",
    "df['IsPeakHour'] = df['Hour'].isin([7, 8, 9, 17, 18, 19, 20])\n",
    "\n",
    "# Weekend indicator\n",
    "df['IsWeekend'] = df['DayOfWeek'].isin([6, 7])\n",
    "\n",
    "# Add engineered features to feature list\n",
    "features.extend(['Hour', 'IsInternational', 'IsPeakHour', 'IsWeekend', 'TimeOfDay'])\n",
    "\n",
    "# Define categorical features AFTER creating TimeOfDay\n",
    "categorical_features = ['Operating_Airline', 'Origin', 'Dest', 'TimeOfDay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Clean data\n",
    "print(\"üßπ Cleaning data...\")\n",
    "initial_count = len(df)\n",
    "df_clean = df.dropna(subset=features + [target])\n",
    "print(f\"   Removed {initial_count - len(df_clean):,} rows with missing values\")\n",
    "print(f\"   Final dataset size: {len(df_clean):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Prepare X and y\n",
    "X = df_clean[features].copy()\n",
    "y = df_clean[target]\n",
    "\n",
    "# Convert boolean to int\n",
    "X['IsInternational'] = X['IsInternational'].astype(int)\n",
    "X['IsPeakHour'] = X['IsPeakHour'].astype(int)\n",
    "X['IsWeekend'] = X['IsWeekend'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Encode categorical features\n",
    "print(\"üè∑Ô∏è  Encoding categorical features...\")\n",
    "encoder = OrdinalEncoder(\n",
    "    handle_unknown='use_encoded_value', \n",
    "    unknown_value=-1,\n",
    "    dtype=int\n",
    ")\n",
    "\n",
    "# Now TimeOfDay exists in the dataframe\n",
    "X[categorical_features] = encoder.fit_transform(X[categorical_features])\n",
    "\n",
    "# Store feature names for later use\n",
    "feature_names = features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Check class distribution\n",
    "print(\"\\nüìä Class Distribution:\")\n",
    "class_counts = y.value_counts()\n",
    "class_percentages = y.value_counts(normalize=True) * 100\n",
    "\n",
    "print(f\"   On-time (0): {class_counts[0]:,} ({class_percentages[0]:.1f}%)\")\n",
    "print(f\"   Delayed (1): {class_counts[1]:,} ({class_percentages[1]:.1f}%)\")\n",
    "print(f\"   Class imbalance ratio: 1:{class_counts[0]/class_counts[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Split data with stratification\n",
    "print(\"üì¶ Splitting data...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y,  # Important for imbalanced datasets\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"   Training set: {len(X_train):,} samples\")\n",
    "print(f\"   Test set: {len(X_test):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Calculate class weights for imbalance handling\n",
    "print(\"‚öñÔ∏è  Calculating class weights...\")\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced', \n",
    "    classes=np.unique(y_train), \n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(f\"   Class weights: {class_weight_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Cross-validation setup\n",
    "print(\"üîÑ Setting up cross-validation...\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Enhanced LightGBM Model\n",
    "print(\"\\nüß† Training Enhanced LightGBM model...\")\n",
    "\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    n_estimators=1000,              # More trees\n",
    "    learning_rate=0.01,            # Lower learning rate\n",
    "    num_leaves=31,                 # Conservative to prevent overfitting\n",
    "    max_depth=-1,                  # No limit on depth\n",
    "    min_child_samples=20,           # Minimum samples in leaf\n",
    "    subsample=0.8,                 # Row subsampling\n",
    "    colsample_bytree=0.8,          # Feature subsampling\n",
    "    reg_alpha=0.1,                 # L1 regularization\n",
    "    reg_lambda=0.1,                # L2 regularization\n",
    "    scale_pos_weight=class_weights[1],  # Handle class imbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    importance_type='gain'\n",
    ")\n",
    "\n",
    "# Train with early stopping\n",
    "print(\"   Training with early stopping...\")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50, verbose=True),\n",
    "        lgb.log_evaluation(period=100)\n",
    "    ],\n",
    "    categorical_feature=categorical_features\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Detailed Evaluation\n",
    "print(\"\\nüìà Model Evaluation:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Basic metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"üéØ Accuracy:  {accuracy*100:.2f}%\")\n",
    "print(f\"üéØ Precision: {precision:.4f}\")\n",
    "print(f\"üéØ Recall:    {recall:.4f}\")\n",
    "print(f\"üéØ F1-Score:  {f1:.4f}\")\n",
    "print(f\"üéØ ROC-AUC:   {roc_auc:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nüìã Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['On-Time', 'Delayed']))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nüî¢ Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"   True Negatives: {tn:,}\")\n",
    "print(f\"   False Positives: {fp:,}\")\n",
    "print(f\"   False Negatives: {fn:,}\")\n",
    "print(f\"   True Positives: {tp:,}\")\n",
    "\n",
    "# Business metrics\n",
    "print(\"\\nüíº Business Metrics:\")\n",
    "print(f\"   Delay Detection Rate: {tp/(tp+fn)*100:.1f}%\")  # Recall\n",
    "print(f\"   False Alarm Rate: {fp/(fp+tn)*100:.1f}%\")     # FP Rate\n",
    "print(f\"   Overall Accuracy: {(tp+tn)/(tp+tn+fp+fn)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Feature Importance\n",
    "print(\"\\nüèÜ Feature Importance:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': model.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"   Top 10 Features:\")\n",
    "for i, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"   {row['feature']:<20}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Save Model and Encoder\n",
    "print(\"\\nüíæ Saving model and encoder...\")\n",
    "MODEL_PATH = 'api/flight_delay_model.joblib'\n",
    "ENCODER_PATH = 'api/flight_data_encoder.joblib'\n",
    "FEATURES_PATH = 'api/model_features.joblib'\n",
    "\n",
    "# Ensure api directory exists\n",
    "os.makedirs('api', exist_ok=True)\n",
    "\n",
    "joblib.dump(model, MODEL_PATH)\n",
    "joblib.dump(encoder, ENCODER_PATH)\n",
    "joblib.dump(feature_names, FEATURES_PATH)\n",
    "\n",
    "print(f\"‚úÖ Model saved to {MODEL_PATH}\")\n",
    "print(f\"‚úÖ Encoder saved to {ENCODER_PATH}\")\n",
    "print(f\"‚úÖ Features saved to {FEATURES_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Save training metrics\n",
    "metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1,\n",
    "    'roc_auc': roc_auc,\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'feature_importance': feature_importance.to_dict(),\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'dataset_size': len(df_clean),\n",
    "    'class_distribution': {\n",
    "        'on_time': int(class_counts[0]),\n",
    "        'delayed': int(class_counts[1])\n",
    "    }\n",
    "}\n",
    "\n",
    "joblib.dump(metrics, 'api/training_metrics.joblib')\n",
    "print(f\"‚úÖ Training metrics saved to api/training_metrics.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Save current metrics to text file for easy viewing\n",
    "with open('api/model_metrics.txt', 'w') as f:\n",
    "    f.write(\"FLIGHT DELAY PREDICTION MODEL METRICS\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    f.write(f\"Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Dataset Size: {len(df_clean):,} flights\\n\\n\")\n",
    "    \n",
    "    f.write(\"PERFORMANCE METRICS:\\n\")\n",
    "    f.write(f\"Accuracy:  {accuracy*100:.2f}%\\n\")\n",
    "    f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "    f.write(f\"Recall:    {recall:.4f}\\n\")\n",
    "    f.write(f\"F1-Score:  {f1:.4f}\\n\")\n",
    "    f.write(f\"ROC-AUC:   {roc_auc:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"CLASS DISTRIBUTION:\\n\")\n",
    "    f.write(f\"On-Time:  {class_counts[0]:,} ({class_percentages[0]:.1f}%)\\n\")\n",
    "    f.write(f\"Delayed:  {class_counts[1]:,} ({class_percentages[1]:.1f}%)\\n\\n\")\n",
    "    \n",
    "    f.write(\"CONFUSION MATRIX:\\n\")\n",
    "    f.write(f\"True Negatives:  {tn:,}\\n\")\n",
    "    f.write(f\"False Positives: {fp:,}\\n\")\n",
    "    f.write(f\"False Negatives: {fn:,}\\n\")\n",
    "    f.write(f\"True Positives:  {tp:,}\\n\\n\")\n",
    "    \n",
    "    f.write(\"TOP 10 FEATURES:\\n\")\n",
    "    for i, row in feature_importance.head(10).iterrows():\n",
    "        f.write(f\"{row['feature']:<20}: {row['importance']:.4f}\\n\")\n",
    "\n",
    "print(f\"‚úÖ Metrics saved to api/model_metrics.txt\")\n",
    "\n",
    "print(\"\\nüéâ Model training completed successfully!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üìã Summary:\")\n",
    "print(f\"   ‚Ä¢ Model achieved {f1:.4f} F1-score\")\n",
    "print(f\"   ‚Ä¢ Can detect {recall:.1%} of delayed flights\")\n",
    "print(f\"   ‚Ä¢ False alarm rate: {fp/(fp+tn):.1%}\")\n",
    "print(f\"   ‚Ä¢ Model saved and ready for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
